import streamlit as st
from PIL import Image
from io import BytesIO
from PyPDF2 import PdfReader
import fitz
import pytesseract
from datetime import datetime
import re
import time
import pandas as pd
import random
from urllib.parse import quote_plus
import asyncio
import json

# --- NEW: Import gTTS ---
from gtts import gTTS

# Import the agent logic
from agent import build_agent, file_analysis_tool

# --- NEW: A helper function to generate audio in memory ---
def generate_audio_from_text(text: str) -> bytes | None:
Â  Â  """Generates MP3 audio from text and returns it as bytes."""
Â  Â  # Clean text to remove markdown for better speech
Â  Â  text = re.sub(r'(\*\*|##|###|####|`|```)', '', text)
Â  Â  if not text or not text.strip():
Â  Â  Â  Â  return None
Â  Â  try:
Â  Â  Â  Â  audio_fp = BytesIO()
Â  Â  Â  Â  tts = gTTS(text=text, lang='en')
Â  Â  Â  Â  tts.write_to_fp(audio_fp)
Â  Â  Â  Â  audio_fp.seek(0)
Â  Â  Â  Â  return audio_fp.getvalue()
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"Error generating TTS audio: {e}")
Â  Â  Â  Â  return None

# --- NEW: A custom function to create a copy-to-clipboard button ---
def create_copy_button(text_to_copy: str, button_key: str):
Â  Â  """
Â  Â  Creates a button in Streamlit that copies the given text to the clipboard.
Â  Â  """
Â  Â  # Unique IDs for HTML elements
Â  Â  button_id = f"copy_btn_{button_key}"
Â  Â  text_id = f"text_{button_key}"

Â  Â  # The HTML part: a hidden element to hold the text and a button
Â  Â  html_code = f"""
Â  Â  Â  Â  <textarea id="{text_id}" style="position: absolute; left: -9999px;">{text_to_copy}</textarea>
Â  Â  Â  Â  <button id="{button_id}">Copy Text</button>
Â  Â  """

Â  Â  # The JavaScript part: finds the elements and adds the copy logic
Â  Â  js_code = f"""
Â  Â  Â  Â  <script>
Â  Â  Â  Â  Â  Â  document.getElementById("{button_id}").addEventListener("click", function() {{
Â  Â  Â  Â  Â  Â  Â  Â  var text = document.getElementById("{text_id}").value;
Â  Â  Â  Â  Â  Â  Â  Â  navigator.clipboard.writeText(text).then(function() {{
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var btn = document.getElementById("{button_id}");
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var originalText = btn.innerHTML;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  btn.innerHTML = 'Copied!';
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  setTimeout(function() {{
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  btn.innerHTML = originalText;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }}, 2000);
Â  Â  Â  Â  Â  Â  Â  Â  }}, function(err) {{
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.error('Could not copy text: ', err);
Â  Â  Â  Â  Â  Â  Â  Â  }});
Â  Â  Â  Â  Â  Â  }});
Â  Â  Â  Â  </script>
Â  Â  """
Â  Â Â 
Â  Â  # Combine and render using st.components.v1.html
Â  Â  st.components.v1.html(html_code + js_code, height=50)

# =====================
# Page Config and Setup
# =====================
st.set_page_config(page_title="ğŸ¤– AI Agent Workshop", page_icon="ğŸ§ ", layout="wide")

# --- Securely load API keys from Streamlit Secrets ---
try:
Â  Â  google_api_key = st.secrets["GOOGLE_API_KEY"]
Â  Â  pollinations_token = st.secrets["POLLINATIONS_TOKEN"]
Â  Â  groq_api_key = st.secrets["GROQ_API_KEY"]
Â  Â  tavily_api_key = st.secrets["TAVILY_API_KEY"]
except KeyError as e:
Â  Â  st.error(f"âŒ Missing Secret: {e}. Please add it to your Streamlit Secrets.")
Â  Â  st.stop()

# ===============================================
# Initialize Session State for Chat and Metrics
# ===============================================
if "messages" not in st.session_state:
Â  Â  st.session_state.messages = []
# --- NEW: Add a key to store the agent's trace ---
if "trajectory" not in st.session_state:
Â  Â  st.session_state.trajectory = []
if "metrics" not in st.session_state:
Â  Â  st.session_state.metrics = {
Â  Â  Â  Â  "total_requests": 0,
Â  Â  Â  Â  "tool_usage": {"Comparison": 0, "Image Gen": 0, "Web Search": 0, "File Analysis": 0},
Â  Â  Â  Â  "total_latency": 0.0,
Â  Â  Â  Â  "average_latency": 0.0,
Â  Â  Â  Â  "accuracy_feedback": {"ğŸ‘": 0, "ğŸ‘": 0},
Â  Â  Â  Â  "last_query_details": {}
Â  Â  }

# =====================
# Main Application UI & Sidebar (Unchanged)
# =====================
st.title("ğŸ§  AI Agent Workshop")
st.write("I can search the web, create images, analyze documents, and more!")

with st.sidebar:
Â  Â  st.header("ğŸ” Google Search")
Â  Â  search_query = st.text_input("Search the web directly...", key="google_search")
Â  Â  if st.button("Search"):
Â  Â  Â  Â  if search_query:
Â  Â  Â  Â  Â  Â  encoded_query = quote_plus(search_query)
Â  Â  Â  Â  Â  Â  search_url = f"[https://www.google.com/search?q=](https://www.google.com/search?q=){encoded_query}"
Â  Â  Â  Â  Â  Â  st.markdown(f'<a href="{search_url}" target="_blank">Open Google search results</a>', unsafe_allow_html=True)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.warning("Please enter a search query.")

Â  Â  st.header("ğŸ“‚ File Analysis")
Â  Â  uploaded_file = st.file_uploader("Upload a file to ask questions about it", type=["pdf", "txt", "py", "js", "html", "css"])
Â  Â Â 
Â  Â  st.header("ğŸ§­ Utilities")
Â  Â  if st.button("Clear Chat History & Reset Metrics"):
Â  Â  Â  Â  st.session_state.messages = []
Â  Â  Â  Â  st.session_state.trajectory = [] # --- ADDED: Clear trajectory on reset ---
Â  Â  Â  Â  st.session_state.metrics = {
Â  Â  Â  Â  Â  Â  "total_requests": 0, "tool_usage": {"Comparison": 0, "Image Gen": 0, "Web Search": 0, "File Analysis": 0},
Â  Â  Â  Â  Â  Â  "total_latency": 0.0, "average_latency": 0.0, "accuracy_feedback": {"ğŸ‘": 0, "ğŸ‘": 0}, "last_query_details": {}
Â  Â  Â  Â  }
Â  Â  Â  Â  st.rerun()

Â  Â  st.markdown("### ğŸ’¡ AI Tip of the Day")
Â  Â  st.info(random.choice([
Â  Â  Â  Â  "The Comparison tool uses both Gemini 1.5 Flash and Llama 3.1 8B for a robust answer.",
Â  Â  Â  Â  "Ask about current events to see the Web Search tool in action!",
Â  Â  Â  Â  "Upload a Python file and ask for a score to test File Analysis."
Â  Â  ]))
Â  Â Â 
Â  Â  st.markdown("### ğŸ•’ Live Server Time")
Â  Â  st.info(datetime.now().strftime("%d %B %Y, %I:%M:%S %p"))

Â  Â  st.header("ğŸ¤– Model Benchmarks")
Â  Â  with st.expander("See Industry Benchmark Scores"):
Â  Â  Â  Â  st.markdown("**Note:** These are public scores for the models used in this agent's Comparison tool.")
Â  Â  Â  Â  benchmark_data = {
Â  Â  Â  Â  Â  Â  "MMLU": {"Llama-3.1-8B Instant": 74.2, "Gemini-2.5 Flash": 82.1, "help": "Measures general knowledge and problem-solving."},
Â  Â  Â  Â  Â  Â  "HumanEval": {"Llama-3.1-8B Instant": 70.3, "Gemini-2.5 Flash": 83.5, "help": "Measures Python code generation ability."},
Â  Â  Â  Â  Â  Â  "GSM8K": {"Llama-3.1-8B Instant": 84.2, "Gemini-2.5 Flash": 91.1, "help": "Measures grade-school math reasoning."}
Â  Â  Â  Â  }
Â  Â  Â  Â  for bench, scores in benchmark_data.items():
Â  Â  Â  Â  Â  Â  llama_score, flash_score = scores["Llama-3.1-8B Instant"], scores["Gemini-2.5 Flash"]
Â  Â  Â  Â  Â  Â  st.markdown(f"**{bench}**")
Â  Â  Â  Â  Â  Â  c1, c2 = st.columns(2)
Â  Â  Â  Â  Â  Â  c1.metric("Llama-3.1-8B Instant (Groq)", f"{llama_score}%", delta=f"{round(llama_score - flash_score, 1)}%", help=scores["help"])
Â  Â  Â  Â  Â  Â  c2.metric("Gemini-2.5 Flash", f"{flash_score}%", delta=f"{round(flash_score - llama_score, 1)}%", help=scores["help"])

Â  Â  st.header("ğŸ“Š Live Agent Performance")
Â  Â  metrics = st.session_state.metrics
Â  Â  col1, col2 = st.columns(2)
Â  Â  col1.metric("Total Requests", metrics["total_requests"])
Â  Â  col2.metric("Avg. Latency", f"{metrics['average_latency']:.2f} s")
Â  Â  st.subheader("ğŸ“ˆ Live App Accuracy (User Feedback)")
Â  Â  total_feedback = metrics["accuracy_feedback"]["ğŸ‘"] + metrics["accuracy_feedback"]["ğŸ‘"]
Â  Â  if total_feedback > 0:
Â  Â  Â  Â  positive_rate = (metrics["accuracy_feedback"]["ğŸ‘"] / total_feedback) * 100
Â  Â  Â  Â  st.metric("Positive Feedback Rate", f"{positive_rate:.1f}%", help="Based on user ğŸ‘/ğŸ‘ clicks.")
Â  Â  else:
Â  Â  Â  Â  st.info("No feedback yet to calculate accuracy.")
Â  Â  st.subheader("ğŸ› ï¸ Tool Usage")
Â  Â  if metrics["total_requests"] > 0:
Â  Â  Â  Â  tool_df = pd.DataFrame(list(metrics["tool_usage"].items()), columns=['Tool', 'Count'])
Â  Â  Â  Â  st.bar_chart(tool_df.set_index('Tool'))
Â  Â  with st.expander("ğŸ•µï¸ See Last Query Details"):
Â  Â  Â  Â  st.json(metrics["last_query_details"])


# ===================================================================
# --- MODIFIED: Main Chat Display Logic with On-Demand Audio Button ---
# ===================================================================
for i, message in enumerate(st.session_state.messages):
Â  Â  with st.chat_message(message["role"]):
Â  Â  Â  Â  # --- Display Text Response ---
Â  Â  Â  Â  if "text" in message:
Â  Â  Â  Â  Â  Â  st.markdown(message["text"])
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- NEW: On-Demand Audio Logic ---
Â  Â  Â  Â  Â  Â  if message["role"] == "assistant":
Â  Â  Â  Â  Â  Â  Â  Â  audio_bytes = message.get("audio_bytes")
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if audio_bytes:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # If audio is generated, show the player
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.audio(audio_bytes, format="audio/mp3")
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # If no audio, show the "Listen" button
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button("ğŸ§ Listen", key=f"listen_btn_{i}"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("Generating audio..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Generate audio
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_audio_bytes = generate_audio_from_text(message["text"])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if new_audio_bytes:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Update the message in session state
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages[i]["audio_bytes"] = new_audio_bytes
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Rerun to display the audio player
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("Could not generate audio.")

Â  Â  Â  Â  Â  Â  Â  Â  # Add the copy button
Â  Â  Â  Â  Â  Â  Â  Â  create_copy_button(message["text"], button_key=f"text_copy_{i}")

Â  Â  Â  Â  # --- Display Image with a Download Button ---
Â  Â  Â  Â  if "image_bytes" in message:
Â  Â  Â  Â  Â  Â  img = Image.open(BytesIO(message["image_bytes"]))
Â  Â  Â  Â  Â  Â  st.image(img, caption=message.get("caption"))
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  label="â¬‡ï¸ Download Image",
Â  Â  Â  Â  Â  Â  Â  Â  data=message["image_bytes"],
Â  Â  Â  Â  Â  Â  Â  Â  file_name=f"generated_image_{i}.png",
Â  Â  Â  Â  Â  Â  Â  Â  mime="image/png",
Â  Â  Â  Â  Â  Â  Â  Â  key=f"download_btn_{i}"
Â  Â  Â  Â  Â  Â  )

# =================================================================================
# --- AGDebugger Logic (Unchanged) ---
# =================================================================================
async def run_agent_and_capture_trajectory(agent, prompt):
Â  Â  """
Â  Â  Runs the agent using astream_events and captures a detailed trace of its execution,
Â  Â  including inputs and outputs for each step.
Â  Â  """
Â  Â  trace_steps = []
Â  Â  current_step = {}
Â  Â  final_response = None
Â  Â  tool_used = "N/A"

Â  Â  async for event in agent.astream_events({"query": prompt}, version="v1"):
Â  Â  Â  Â  kind = event["event"]
Â  Â  Â  Â Â 
Â  Â  Â  Â  if kind == "on_chain_start":
Â  Â  Â  Â  Â  Â  if event["name"] != "LangGraph":
Â  Â  Â  Â  Â  Â  Â  Â  current_step = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "name": event["name"],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "input": event["data"].get("input"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "output": None
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  # Capture the friendly tool name
Â  Â  Â  Â  Â  Â  Â  Â  if event['name'] == "comparison_chat": tool_used = "Comparison"
Â  Â  Â  Â  Â  Â  Â  Â  elif event['name'] == "image_generator": tool_used = "Image Gen"
Â  Â  Â  Â  Â  Â  Â  Â  elif event['name'] == "web_search": tool_used = "Web Search"

Â  Â  Â  Â  if kind == "on_chain_end":
Â  Â  Â  Â  Â  Â  if event["name"] != "LangGraph":
Â  Â  Â  Â  Â  Â  Â  Â  output = event["data"].get("output")
Â  Â  Â  Â  Â  Â  Â  Â  if current_step.get("name") == event["name"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_step["output"] = output
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  trace_steps.append(current_step)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_step = {}
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(output, dict) and 'final_response' in output:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_response = output['final_response']

Â  Â  return final_response, trace_steps, tool_used

def pretty_print_dict(d):
Â  Â  def safe_converter(o):
Â  Â  Â  Â  if isinstance(o, (Image.Image, bytes)):
Â  Â  Â  Â  Â  Â  return f"<{type(o).__name__} object>"
Â  Â  Â  Â  return str(o)
Â  Â Â 
Â  Â  if not isinstance(d, dict):
Â  Â  Â  Â  return f"```\n{str(d)}\n```"
Â  Â  Â  Â Â 
Â  Â  return "```json\n" + json.dumps(d, indent=2, default=safe_converter) + "\n```"


# =================================================================================
# --- MODIFIED: Main Chat Input Logic (REMOVED automatic audio generation) ---
# =================================================================================
if prompt := st.chat_input("Ask about the latest news, create an image, or query a file..."):
Â  Â  st.session_state.messages.append({"role": "user", "text": prompt})
Â  Â Â 
Â  Â  with st.chat_message("assistant"):
Â  Â  Â  Â  with st.spinner("Agent is working..."):
Â  Â  Â  Â  Â  Â  start_time = time.time()
Â  Â  Â  Â  Â  Â  tool_used_key = ""

Â  Â  Â  Â  Â  Â  if uploaded_file:
Â  Â  Â  Â  Â  Â  Â  Â  # --- This is the File Analysis Path ---
Â  Â  Â  Â  Â  Â  Â  Â  tool_used_key = "File Analysis"
Â  Â  Â  Â  Â  Â  Â  Â  file_bytes = uploaded_file.read()
Â  Â  Â  Â  Â  Â  Â  Â  file_text = ""
Â  Â  Â  Â  Â  Â  Â  Â  if "pdf" in uploaded_file.type:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  reader = PdfReader(BytesIO(file_bytes))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for page in reader.pages: file_text += page.extract_text() or ""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not file_text.strip():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("No text layer found, performing OCR...")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  doc = fitz.open(stream=file_bytes, filetype="pdf")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for page in doc:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pix = page.get_pixmap()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  img = Image.open(BytesIO(pix.tobytes("png")))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_text += pytesseract.image_to_string(img)
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_text = file_bytes.decode("utf-8", errors="ignore")
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  response_stream = file_analysis_tool(prompt, file_text, google_api_key)
Â  Â  Â  Â  Â  Â  Â  Â  full_response = st.write_stream(response_stream)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # --- MODIFIED: Store None for audio, it will be generated on-demand ---
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "assistant", "text": full_response, "audio_bytes": None})
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  # --- This is the Agent Path ---
Â  Â  Â  Â  Â  Â  Â  Â  agent = build_agent(google_api_key, groq_api_key, pollinations_token, tavily_api_key)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  final_response, trace_steps, tool_used_key = asyncio.run(run_agent_and_capture_trajectory(agent, prompt))
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.trajectory.append({"prompt": prompt, "steps": trace_steps})

Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(final_response, str):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(final_response)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # --- MODIFIED: Store None for audio ---
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "assistant", "text": final_response, "audio_bytes": None})
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  elif isinstance(final_response, dict) and "image" in final_response:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  img_data = final_response["image"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  buf = BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  img_data.save(buf, format="PNG")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  byte_im = buf.getvalue()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.image(byte_im, caption=final_response.get("caption", prompt))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "role": "assistant", "image_bytes": byte_im, "text": f"Image generated for: *{prompt}*",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "caption": final_response.get("caption", prompt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # No audio for image-only responses
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  error_message = final_response.get("error", "Sorry, something went wrong.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"Error: {error_message}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # --- MODIFIED: Store None for audio ---
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "assistant", "text": f"Error: {error_message}", "audio_bytes": None})
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Metrics Recording (logic is unchanged) ---
Â  Â  Â  Â  Â  Â  # This timer now stops *before* any audio is generated, giving an accurate latency.
Â  Â  Â  Â  Â  Â  end_time = time.time()
Â  Â  Â  Â  Â  Â  latency = end_time - start_time
Â  Â  Â  Â  Â  Â  metrics = st.session_state.metrics
Â  Â  Â  Â  Â  Â  metrics["total_requests"] += 1
Â  Â  Â  Â  Â  Â  if tool_used_key and tool_used_key in metrics["tool_usage"]:
Â  Â  Â  Â  Â  Â  Â  Â  metrics["tool_usage"][tool_used_key] += 1
Â  Â  Â  Â  Â  Â  metrics["total_latency"] += latency
Â  Â  Â  Â  Â  Â  metrics["average_latency"] = metrics["total_latency"] / metrics["total_requests"]
Â  Â  Â  Â  Â  Â  metrics["last_query_details"] = {
Â  Â  Â  Â  Â  Â  Â  Â  "timestamp": datetime.now().isoformat(), "prompt": prompt,
Â  Â  Â  Â  Â  Â  Â  Â  "tool_used": tool_used_key, "latency_seconds": round(latency, 2)
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  st.rerun()

# --- MODIFIED: Debug View (Unchanged from your version) ---
if st.session_state.trajectory:
Â  Â  with st.expander("ğŸ•µï¸ Agent Trajectory / Debug View", expanded=False):
Â  Â  Â  Â  for run in reversed(st.session_state.trajectory):
Â  Â  Â  Â  Â  Â  st.markdown(f"#### Prompt: *'{run.get('prompt', 'N/A')}'*")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  steps = run.get('steps', [])
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  for step in steps:
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"##### ğŸ¬ Step: `{step.get('name', 'Unknown Step')}`")
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  with st.container(border=True):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("**Input:**")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(pretty_print_dict(step.get('input', {})), unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  with st.container(border=True):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("**Output:**")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(pretty_print_dict(step.get('output', {})), unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  st.markdown("---")

# --- Feedback buttons logic (Unchanged) ---
if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
Â  Â  message_id = len(st.session_state.messages) - 1

Â  Â  if f"feedback_{message_id}" not in st.session_state:
Â  Â  Â  Â  feedback_cols = st.columns(10)
Â  Â  Â  Â  if feedback_cols[0].button("ğŸ‘", key=f"good_{message_id}"):
Â  Â  Â  Â  Â  Â  st.session_state.metrics["accuracy_feedback"]["ğŸ‘"] += 1
Â  Â  Â  Â  Â  Â  st.session_state[f"feedback_{message_id}"] = "given"
Â  Â  Â  Â  Â  Â  st.toast("Thanks for your feedback!")
Â  Â  Â  Â  Â  Â  time.sleep(1)
Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  Â  Â  if feedback_cols[1].button("ğŸ‘", key=f"bad_{message_id}"):
Â  Â  Â  Â  Â  Â  st.session_state.metrics["accuracy_feedback"]["ğŸ‘"] += 1
Â  Â  Â  Â  Â  Â  st.session_state[f"feedback_{message_id}"] = "given"
Â  Â  Â  Â  Â  Â  st.toast("Thanks for your feedback!")
Â  Â  Â  Â  Â  Â  time.sleep(1)
Â  Â  Â  Â  Â  Â  st.rerun() . 
